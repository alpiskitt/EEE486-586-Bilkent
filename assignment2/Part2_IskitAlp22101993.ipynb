{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vo44yrVwXnbq"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets transformers optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fu6erobKLReX"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets transformers optuna\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.utils.data as Data\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup, logging\n",
    "import optuna\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHz2V1yRXbPC"
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.backends.cuda.is_built():\n",
    "        print(\"CUDA\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_built():\n",
    "        print(\"mps\")\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        raise Exception(\"GPU is not avalaible!\")\n",
    "    return device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xb_l6ZmBAEHm"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "\n",
    "def train_eval_loop(\n",
    "    model, loader, optimizer, scheduler, device, n_epochs=2, seed_val=42\n",
    "):\n",
    "    # Set the seed value all over the place to make this reproducible.\n",
    "\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    loss_values = []\n",
    "    t00 = time.time()\n",
    "    for epoch_i in range(0, n_epochs):\n",
    "        print(\"\")\n",
    "        print(\"======== Epoch {:} / {:} ========\".format(epoch_i + 1, n_epochs))\n",
    "        print(\"Training...\")\n",
    "\n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Reset the total loss for this epoch.\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(loader[\"train\"]):\n",
    "            # print('Memory Usage:')\n",
    "            # print('Allocated:', round(torch.mps.driver_allocated_memory()/1024**3,1), 'GB')\n",
    "\n",
    "            b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "            model.zero_grad()\n",
    "\n",
    "            loss = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels).loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0, this is to help prevent the \"exploding gradients\" problem.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_loss / len(loader[\"train\"])\n",
    "        loss_values.append(avg_train_loss)\n",
    "\n",
    "        print(\"\\nAverage training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(format_time(time.time() - t00)))\n",
    "\n",
    "        print(\"\\nRunning Validation...\")\n",
    "        t0 = time.time()\n",
    "        model.eval()\n",
    "        val_acc, nb_eval_steps = 0, 0\n",
    "\n",
    "        for batch in loader[\"validation\"]:\n",
    "            b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "            # print('Memory Usage:')\n",
    "            # print('Allocated:', round(torch.mps.driver_allocated_memory()/1024**3,1), 'GB')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(b_input_ids, attention_mask=b_input_mask).logits\n",
    "\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            logits = np.argmax(logits, axis=1).flatten()\n",
    "            label_ids = b_labels.to(\"cpu\").numpy()\n",
    "\n",
    "            val_acc += accuracy_score(logits, label_ids)\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "        val_acc = 100 * (val_acc / nb_eval_steps)\n",
    "        print(\"  Validation ACC: {0:.2f}\".format(val_acc))\n",
    "        print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    return val_acc, loss_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FlNeWQ9zXgU1"
   },
   "outputs": [],
   "source": [
    "def init_loader(max_length=16, batch_size=32, test_size=0.2, random_state=2023):\n",
    "    model_checkpoint = \"bert-base-uncased\"\n",
    "\n",
    "    dataset = load_dataset(\"glue\", \"rte\")\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "    # Define dictionaries to store processed data\n",
    "    df_s, x, y = {}, {}, {}\n",
    "    input_ids, attention_mask = {}, {}\n",
    "    datasets, loader = {}, {}\n",
    "\n",
    "    max_length = 128  # Set max sequence length\n",
    "\n",
    "    for split in [\"train\", \"validation\", \"test\"]:\n",
    "        # Convert dataset to pandas\n",
    "        df_s[split] = dataset[split].to_pandas()\n",
    "\n",
    "        # Extract premise and hypothesis for RTE\n",
    "        premise = dataset[split][\"sentence1\"]\n",
    "        hypothesis = dataset[split][\"sentence2\"]\n",
    "        y[split] = dataset[split][\"label\"]  # Labels\n",
    "\n",
    "        # Store sentence pairs\n",
    "        x[split] = list(zip(premise, hypothesis))\n",
    "\n",
    "        # Tokenize as sentence pairs\n",
    "        input= tokenizer(\n",
    "            premise,\n",
    "            hypothesis,\n",
    "            max_length=max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        input_ids[split], attention_mask[split] = input.input_ids, input.attention_mask\n",
    "\n",
    "        datasets[split] = Data.TensorDataset(\n",
    "            input_ids[split], attention_mask[split], torch.LongTensor(y[split])\n",
    "        )\n",
    "\n",
    "        loader[split] = Data.DataLoader(\n",
    "            datasets[split], batch_size=batch_size, shuffle=False\n",
    "        )\n",
    "    return loader, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQtgoNL8XQ9z"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "\n",
    "def init_objects(\n",
    "    lr, n_epochs, max_length=16, batch_size=32, test_size=0.2, random_state=2023\n",
    "):\n",
    "    loader, _ = init_loader(max_length=max_length, batch_size=batch_size)\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, eps=1e-8)\n",
    "\n",
    "    total_steps = len(loader[\"train\"]) * n_epochs\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    "    )\n",
    "    return model, loader, optimizer, scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KtLbcOKCYX0L",
    "outputId": "39d31893-108e-4414-8a49-2ec8ed3671fe"
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "!pip install optuna\n",
    "import torch\n",
    "import optuna\n",
    "from transformers import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3c6c46e994bb4cd98624dd5be02218f3",
      "77a4d7a1e6ca4860ae7cf0f2b7a327b4",
      "779dbac6e10e4f5d85c2aa0f445be98e",
      "106d8f27a6224a98aa932c1d9417530b",
      "830947b4a8c944a3a4493d72bfe3033f",
      "07e4c1bb67f1427e8587fc6dcbdd9de5",
      "e359b14561494e7e87e258a165ed1793",
      "6c9ae75c0f6942a283cfe57e2d287226",
      "1981aa094da242b892b4f08a897e9b96",
      "5202bcb785d441f690b852a8fcac8731",
      "bb20ebd93859482eb276c52c9cb5d5d1"
     ]
    },
    "id": "CoTBn9yXKS6k",
    "outputId": "9eb5fdbe-b6ac-4d93-f483-884d07cc231f"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup, logging\n",
    "import torch.nn as nn\n",
    "\n",
    "# -----------------------------\n",
    "# Attention Pooling Implementation\n",
    "# -----------------------------\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(AttentionPooling, self).__init__()\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        # hidden_states: [batch_size, seq_length, hidden_size]\n",
    "        # Compute attention scores for each token\n",
    "        scores = self.attention(hidden_states).squeeze(-1)  # [batch_size, seq_length]\n",
    "        # Mask padded tokens (attention_mask==0)\n",
    "        scores = scores.masked_fill(attention_mask == 0, -1e9)\n",
    "        # Compute attention weights\n",
    "        attn_weights = torch.softmax(scores, dim=1)  # [batch_size, seq_length]\n",
    "        # Weighted sum of hidden states\n",
    "        pooled_output = torch.sum(hidden_states * attn_weights.unsqueeze(-1), dim=1)\n",
    "        return pooled_output\n",
    "\n",
    "# -----------------------------\n",
    "# Unified Custom BERT Model with Selectable Pooling\n",
    "# -----------------------------\n",
    "class CustomBertForSequenceClassification(nn.Module):\n",
    "    def __init__(self, model_checkpoint, num_labels=2, dropout_prob=0.1, pooling_type='mean_max'):\n",
    "        \"\"\"\n",
    "        pooling_type options:\n",
    "            'mean_max'  : Concatenates mean and max pooling (original approach)\n",
    "            'attention' : Uses attention-based pooling\n",
    "        \"\"\"\n",
    "        from transformers import BertModel\n",
    "        super(CustomBertForSequenceClassification, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_checkpoint)\n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "        self.pooling_type = pooling_type\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "        if pooling_type == 'mean_max':\n",
    "            # Using both mean and max pooling: final size is 2 * hidden_size\n",
    "            self.classifier = nn.Linear(hidden_size * 2, num_labels)\n",
    "        elif pooling_type == 'attention':\n",
    "            # Using attention pooling: final size remains hidden_size\n",
    "            self.attention_pool = AttentionPooling(hidden_size)\n",
    "            self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported pooling type. Choose 'mean_max' or 'attention'.\")\n",
    "\n",
    "        self.loss_fct = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state  # [batch_size, seq_length, hidden_size]\n",
    "\n",
    "        if self.pooling_type == 'mean_max':\n",
    "            # Mean pooling\n",
    "            mean_pool = torch.mean(last_hidden_state, dim=1)\n",
    "            # Max pooling\n",
    "            max_pool, _ = torch.max(last_hidden_state, dim=1)\n",
    "            # Concatenate pooled representations\n",
    "            pooled_output = torch.cat((mean_pool, max_pool), dim=1)\n",
    "        elif self.pooling_type == 'attention':\n",
    "            # Apply attention pooling\n",
    "            pooled_output = self.attention_pool(last_hidden_state, attention_mask)\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fct(logits, labels)\n",
    "\n",
    "        # Mimic Hugging Face model outputs\n",
    "        return type(\"Output\", (object,), {\"loss\": loss, \"logits\": logits})\n",
    "\n",
    "# -----------------------------\n",
    "# Training and Evaluation Functions\n",
    "# -----------------------------\n",
    "def train_eval_loop(model, loader, optimizer, scheduler, device, n_epochs=2, seed_val=42):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    loss_values = []\n",
    "    t00 = time.time()\n",
    "    for epoch_i in range(n_epochs):\n",
    "        print(\"\")\n",
    "        print(\"======== Epoch {:} / {:} ========\".format(epoch_i + 1, n_epochs))\n",
    "        print(\"Training...\")\n",
    "\n",
    "        t0 = time.time()\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(loader[\"train\"]):\n",
    "            b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "            model.zero_grad()\n",
    "\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_loss / len(loader[\"train\"])\n",
    "        loss_values.append(avg_train_loss)\n",
    "\n",
    "        print(\"\\nAverage training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(format_time(time.time() - t00)))\n",
    "\n",
    "        print(\"\\nRunning Validation...\")\n",
    "        t0 = time.time()\n",
    "        model.eval()\n",
    "        val_acc, nb_eval_steps = 0, 0\n",
    "\n",
    "        for batch in loader[\"validation\"]:\n",
    "            b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "            logits = outputs.logits.detach().cpu().numpy()\n",
    "            logits = np.argmax(logits, axis=1).flatten()\n",
    "            label_ids = b_labels.to(\"cpu\").numpy()\n",
    "\n",
    "            val_acc += accuracy_score(logits, label_ids)\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "        val_acc = 100 * (val_acc / nb_eval_steps)\n",
    "        print(\"  Validation ACC: {0:.2f}\".format(val_acc))\n",
    "        print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    return val_acc, loss_values\n",
    "\n",
    "def init_loader(max_length=128, batch_size=32, test_size=0.2, random_state=2023):\n",
    "    model_checkpoint = \"bert-base-uncased\"\n",
    "    dataset = load_dataset(\"glue\", \"rte\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "    df_s, x, y = {}, {}, {}\n",
    "    input_ids, attention_mask = {}, {}\n",
    "    datasets, loader = {}, {}\n",
    "\n",
    "    for split in [\"train\", \"validation\", \"test\"]:\n",
    "        df_s[split] = dataset[split].to_pandas()\n",
    "        premise = dataset[split][\"sentence1\"]\n",
    "        hypothesis = dataset[split][\"sentence2\"]\n",
    "        y[split] = dataset[split][\"label\"]\n",
    "        x[split] = list(zip(premise, hypothesis))\n",
    "        inputs = tokenizer(premise, hypothesis, max_length=max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "        input_ids[split], attention_mask[split] = inputs.input_ids, inputs.attention_mask\n",
    "        datasets[split] = Data.TensorDataset(input_ids[split], attention_mask[split], torch.LongTensor(y[split]))\n",
    "        loader[split] = Data.DataLoader(datasets[split], batch_size=batch_size, shuffle=False)\n",
    "    return loader, y\n",
    "\n",
    "def init_objects(lr, n_epochs, max_length=128, batch_size=32, test_size=0.2, random_state=2023, pooling_type='mean_max'):\n",
    "    loader, _ = init_loader(max_length=max_length, batch_size=batch_size)\n",
    "    model_checkpoint = \"bert-base-uncased\"\n",
    "    # Choose pooling_type: 'mean_max' or 'attention'\n",
    "    model = CustomBertForSequenceClassification(model_checkpoint, num_labels=2, pooling_type=pooling_type)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, eps=1e-8)\n",
    "    total_steps = len(loader[\"train\"]) * n_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "    return model, loader, optimizer, scheduler\n",
    "\n",
    "# -----------------------------\n",
    "# Main Execution\n",
    "# -----------------------------\n",
    "!pip install optuna\n",
    "import optuna\n",
    "\n",
    "lr = 2e-5\n",
    "n_epochs = 1\n",
    "max_length = 128\n",
    "batch_size = 128\n",
    "test_size = 0.2\n",
    "random_state = 2023\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set pooling_type here: 'mean_max' or 'attention'\n",
    "pooling_type = 'attention'  # change to 'mean_max' to use the original method\n",
    "\n",
    "model, loader, optimizer, scheduler = init_objects(lr, n_epochs, max_length, batch_size, test_size, random_state, pooling_type=pooling_type)\n",
    "model.to(device)\n",
    "\n",
    "_, _ = train_eval_loop(model, loader, optimizer, scheduler, device, n_epochs=n_epochs, seed_val=42)\n",
    "\n",
    "# Hyperparameter optimization using Optuna remains unchanged.\n",
    "param_dict = {\n",
    "    \"lr\": [1e-5, 1e-4],\n",
    "    \"n_epochs\": [5, 10, 15],\n",
    "    \"max_length\": [32, 64, 128, 256],\n",
    "}\n",
    "\n",
    "class BertObjective:\n",
    "    def __init__(self, d, device, pooling_type):\n",
    "        self.d = d\n",
    "        self.device = device\n",
    "        self.pooling_type = pooling_type\n",
    "\n",
    "    def __call__(self, trial: optuna.trial.Trial):\n",
    "        self.lr = trial.suggest_float(\"lr\", self.d[\"lr\"][0], self.d[\"lr\"][1], log=True)\n",
    "        self.n_epochs = trial.suggest_categorical(\"n_epochs\", self.d[\"n_epochs\"])\n",
    "        self.max_length = trial.suggest_categorical(\"max_length\", self.d[\"max_length\"])\n",
    "\n",
    "        model, loader, optimizer, scheduler = init_objects(self.lr, self.n_epochs, self.max_length, pooling_type=self.pooling_type)\n",
    "        model.to(self.device)\n",
    "        val_acc, _ = train_eval_loop(model, loader, optimizer, scheduler, self.device, self.n_epochs)\n",
    "        return val_acc\n",
    "\n",
    "study = optuna.create_study(study_name=\"Study 0\", direction=\"maximize\")\n",
    "study.optimize(BertObjective(param_dict, device, pooling_type=pooling_type), n_trials=30)\n",
    "\n",
    "# Train again with best parameters from Optuna\n",
    "lr = study.best_params[\"lr\"]\n",
    "n_epochs = study.best_params[\"n_epochs\"]\n",
    "max_length = study.best_params[\"max_length\"]\n",
    "\n",
    "model, loader, optimizer, scheduler = init_objects(lr, n_epochs, max_length, batch_size, pooling_type=pooling_type)\n",
    "model.to(device)\n",
    "val_acc, _ = train_eval_loop(model, loader, optimizer, scheduler, device, n_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQcyt2V5nIYJ",
    "outputId": "8bb21112-069c-4162-9291-b212cc010d0b"
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rx14VHIJTygC",
    "outputId": "05971fe2-54ba-40a1-c573-6b2e7a62b7e4"
   },
   "outputs": [],
   "source": [
    "lr = study.best_params[\"lr\"]\n",
    "n_epochs = study.best_params[\"n_epochs\"]\n",
    "max_length = study.best_params[\"max_length\"]\n",
    "\n",
    "model, loader, optimizer, scheduler = init_objects(lr, n_epochs, max_length, batch_size)\n",
    "model.to(device)\n",
    "val_acc, _ = train_eval_loop(model, loader, optimizer, scheduler, device, n_epochs)\n",
    "# Obtain Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "mwOOYViYnLwP",
    "outputId": "363333a7-6916-46e7-9bcf-051949662a74"
   },
   "outputs": [],
   "source": [
    "# Plot the training loss curve\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(_, marker='o', label=\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JI3QSWXMgyxU",
    "outputId": "88efcc44-1a2f-4944-d65a-2ff4e8dae47e"
   },
   "outputs": [],
   "source": [
    "# Print best hyperparameters and best validation accuracy for Part 2\n",
    "print(\"Best parameters from hyperparameter search with {} pooling:\".format(pooling_type))\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"Best validation accuracy: {study.best_trial.value:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4AdwGSsokm6",
    "outputId": "f7b7833b-2735-4445-99dd-0ef5c2fbd0a8"
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters from hyperparameter search with meanmax:\")\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ObTJolwRgSM2",
    "outputId": "c418bbdb-8fe3-4e13-d929-8679a6d6f586"
   },
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "\n",
    "# Plot the optimization history (objective value vs. trial number)\n",
    "fig_history = vis.plot_optimization_history(study)\n",
    "fig_history.update_layout(title=\"Optuna Optimization History - Part 2 Mean-Max\")\n",
    "fig_history.show()\n",
    "\n",
    "# Plot the parameter importances (which hyperparameters impacted the results most)\n",
    "fig_importance = vis.plot_param_importances(study)\n",
    "fig_importance.update_layout(title=\"Optuna Parameter Importances - Part 2 Mean-Max\")\n",
    "fig_importance.show()\n",
    "\n",
    "# Plot the slice plot to visualize the relationship between hyperparameter values and evaluation metric\n",
    "fig_slice = vis.plot_slice(study)\n",
    "fig_slice.update_layout(title=\"Optuna Slice Plot - Part 2 Mean-Max\")\n",
    "fig_slice.show()\n",
    "\n",
    "# Plot the parallel coordinate plot to inspect the multidimensional search space\n",
    "fig_parallel = vis.plot_parallel_coordinate(study)\n",
    "fig_parallel.update_layout(title=\"Optuna Parallel Coordinate Plot - Part 2 Mean-Max\")\n",
    "fig_parallel.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ecYKMO3lq8Gz",
    "outputId": "fc628c50-d2d2-4f7c-c84e-a1760e790323"
   },
   "outputs": [],
   "source": [
    "# In the same sense, we will use the attention pooling instead of mean max pooling concatenated\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup, logging\n",
    "import torch.nn as nn\n",
    "\n",
    "# -----------------------------\n",
    "# Attention Pooling Implementation\n",
    "# -----------------------------\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(AttentionPooling, self).__init__()\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        # hidden_states: [batch_size, seq_length, hidden_size]\n",
    "        # Compute attention scores for each token\n",
    "        scores = self.attention(hidden_states).squeeze(-1)  # [batch_size, seq_length]\n",
    "        # Mask padded tokens (attention_mask==0)\n",
    "        scores = scores.masked_fill(attention_mask == 0, -1e9)\n",
    "        # Compute attention weights\n",
    "        attn_weights = torch.softmax(scores, dim=1)  # [batch_size, seq_length]\n",
    "        # Weighted sum of hidden states\n",
    "        pooled_output = torch.sum(hidden_states * attn_weights.unsqueeze(-1), dim=1)\n",
    "        return pooled_output\n",
    "\n",
    "# -----------------------------\n",
    "# Unified Custom BERT Model with Selectable Pooling\n",
    "# -----------------------------\n",
    "class CustomBertForSequenceClassification(nn.Module):\n",
    "    def __init__(self, model_checkpoint, num_labels=2, dropout_prob=0.1, pooling_type='attention'):\n",
    "        \"\"\"\n",
    "        pooling_type options:\n",
    "            'mean_max'  : Concatenates mean and max pooling (original approach)\n",
    "            'attention' : Uses attention-based pooling\n",
    "        \"\"\"\n",
    "        from transformers import BertModel\n",
    "        super(CustomBertForSequenceClassification, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_checkpoint)\n",
    "\n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "        self.pooling_type = pooling_type\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "        if pooling_type == 'mean_max':\n",
    "            # Using both mean and max pooling: final size is 2 * hidden_size\n",
    "            self.classifier = nn.Linear(hidden_size * 2, num_labels)\n",
    "        elif pooling_type == 'attention':\n",
    "            # Using attention pooling: final size remains hidden_size\n",
    "            self.attention_pool = AttentionPooling(hidden_size)\n",
    "            self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported pooling type. Choose 'mean_max' or 'attention'.\")\n",
    "\n",
    "        self.loss_fct = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state  # [batch_size, seq_length, hidden_size]\n",
    "\n",
    "        if self.pooling_type == 'mean_max':\n",
    "            # Mean pooling\n",
    "            mean_pool = torch.mean(last_hidden_state, dim=1)\n",
    "            # Max pooling\n",
    "            max_pool, _ = torch.max(last_hidden_state, dim=1)\n",
    "            # Concatenate pooled representations\n",
    "            pooled_output = torch.cat((mean_pool, max_pool), dim=1)\n",
    "        elif self.pooling_type == 'attention':\n",
    "            # Apply attention pooling\n",
    "            pooled_output = self.attention_pool(last_hidden_state, attention_mask)\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fct(logits, labels)\n",
    "\n",
    "        # Mimic Hugging Face model outputs\n",
    "        return type(\"Output\", (object,), {\"loss\": loss, \"logits\": logits})\n",
    "\n",
    "# -----------------------------\n",
    "# Training and Evaluation Functions\n",
    "# -----------------------------\n",
    "def train_eval_loop(model, loader, optimizer, scheduler, device, n_epochs=2, seed_val=42):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    loss_values = []\n",
    "    t00 = time.time()\n",
    "    for epoch_i in range(n_epochs):\n",
    "        print(\"\")\n",
    "        print(\"======== Epoch {:} / {:} ========\".format(epoch_i + 1, n_epochs))\n",
    "        print(\"Training...\")\n",
    "\n",
    "        t0 = time.time()\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(loader[\"train\"]):\n",
    "            b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "            model.zero_grad()\n",
    "\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_loss / len(loader[\"train\"])\n",
    "        loss_values.append(avg_train_loss)\n",
    "\n",
    "        print(\"\\nAverage training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(format_time(time.time() - t00)))\n",
    "\n",
    "        print(\"\\nRunning Validation...\")\n",
    "        t0 = time.time()\n",
    "        model.eval()\n",
    "        val_acc, nb_eval_steps = 0, 0\n",
    "\n",
    "        for batch in loader[\"validation\"]:\n",
    "            b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "            logits = outputs.logits.detach().cpu().numpy()\n",
    "            logits = np.argmax(logits, axis=1).flatten()\n",
    "            label_ids = b_labels.to(\"cpu\").numpy()\n",
    "\n",
    "            val_acc += accuracy_score(logits, label_ids)\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "        val_acc = 100 * (val_acc / nb_eval_steps)\n",
    "        print(\"  Validation ACC: {0:.2f}\".format(val_acc))\n",
    "        print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    return val_acc, loss_values\n",
    "\n",
    "def init_loader(max_length=128, batch_size=32, test_size=0.2, random_state=2023):\n",
    "    model_checkpoint = \"bert-base-uncased\"\n",
    "    dataset = load_dataset(\"glue\", \"rte\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "    df_s, x, y = {}, {}, {}\n",
    "    input_ids, attention_mask = {}, {}\n",
    "    datasets, loader = {}, {}\n",
    "\n",
    "    for split in [\"train\", \"validation\", \"test\"]:\n",
    "        df_s[split] = dataset[split].to_pandas()\n",
    "        premise = dataset[split][\"sentence1\"]\n",
    "        hypothesis = dataset[split][\"sentence2\"]\n",
    "        y[split] = dataset[split][\"label\"]\n",
    "        x[split] = list(zip(premise, hypothesis))\n",
    "        inputs = tokenizer(premise, hypothesis, max_length=max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "        input_ids[split], attention_mask[split] = inputs.input_ids, inputs.attention_mask\n",
    "        datasets[split] = Data.TensorDataset(input_ids[split], attention_mask[split], torch.LongTensor(y[split]))\n",
    "        loader[split] = Data.DataLoader(datasets[split], batch_size=batch_size, shuffle=False)\n",
    "    return loader, y\n",
    "\n",
    "def init_objects(lr, n_epochs, max_length=128, batch_size=32, test_size=0.2, random_state=2023, pooling_type='mean_max'):\n",
    "    loader, _ = init_loader(max_length=max_length, batch_size=batch_size)\n",
    "    model_checkpoint = \"bert-base-uncased\"\n",
    "    # Choose pooling_type: 'mean_max' or 'attention'\n",
    "    model = CustomBertForSequenceClassification(model_checkpoint, num_labels=2, pooling_type=pooling_type)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, eps=1e-8)\n",
    "    total_steps = len(loader[\"train\"]) * n_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "    return model, loader, optimizer, scheduler\n",
    "\n",
    "# -----------------------------\n",
    "# Main Execution\n",
    "# -----------------------------\n",
    "!pip install optuna\n",
    "import optuna\n",
    "\n",
    "lr = 2e-5\n",
    "n_epochs = 1\n",
    "max_length = 128\n",
    "batch_size = 128\n",
    "test_size = 0.2\n",
    "random_state = 2023\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set pooling_type here: 'mean_max' or 'attention'\n",
    "pooling_type = 'attention'  # change to 'mean_max' to use the original method\n",
    "\n",
    "model, loader, optimizer, scheduler = init_objects(lr, n_epochs, max_length, batch_size, test_size, random_state, pooling_type=pooling_type)\n",
    "model.to(device)\n",
    "\n",
    "_, _ = train_eval_loop(model, loader, optimizer, scheduler, device, n_epochs=n_epochs, seed_val=42)\n",
    "\n",
    "# Hyperparameter optimization using Optuna remains unchanged.\n",
    "param_dict = {\n",
    "    \"lr\": [1e-5, 1e-4],\n",
    "    \"n_epochs\": [5, 10, 15],\n",
    "    \"max_length\": [32, 64, 128, 256],\n",
    "}\n",
    "\n",
    "class BertObjective:\n",
    "    def __init__(self, d, device, pooling_type):\n",
    "        self.d = d\n",
    "        self.device = device\n",
    "        self.pooling_type = pooling_type\n",
    "\n",
    "    def __call__(self, trial: optuna.trial.Trial):\n",
    "        self.lr = trial.suggest_float(\"lr\", self.d[\"lr\"][0], self.d[\"lr\"][1], log=True)\n",
    "        self.n_epochs = trial.suggest_categorical(\"n_epochs\", self.d[\"n_epochs\"])\n",
    "        self.max_length = trial.suggest_categorical(\"max_length\", self.d[\"max_length\"])\n",
    "\n",
    "        model, loader, optimizer, scheduler = init_objects(self.lr, self.n_epochs, self.max_length, pooling_type=self.pooling_type)\n",
    "        model.to(self.device)\n",
    "        val_acc, _ = train_eval_loop(model, loader, optimizer, scheduler, self.device, self.n_epochs)\n",
    "        return val_acc\n",
    "\n",
    "study = optuna.create_study(study_name=\"Study 0\", direction=\"maximize\")\n",
    "study.optimize(BertObjective(param_dict, device, pooling_type=pooling_type), n_trials=30)\n",
    "\n",
    "# Train again with best parameters from Optuna\n",
    "lr = study.best_params[\"lr\"]\n",
    "n_epochs = study.best_params[\"n_epochs\"]\n",
    "max_length = study.best_params[\"max_length\"]\n",
    "\n",
    "model, loader, optimizer, scheduler = init_objects(lr, n_epochs, max_length, batch_size, pooling_type=pooling_type)\n",
    "model.to(device)\n",
    "val_acc, _ = train_eval_loop(model, loader, optimizer, scheduler, device, n_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ny8f5X2zffnx",
    "outputId": "2b3f374d-1418-48ac-ab93-6df9faeac217"
   },
   "outputs": [],
   "source": [
    "lr = study.best_params[\"lr\"]\n",
    "n_epochs = study.best_params[\"n_epochs\"]\n",
    "max_length = study.best_params[\"max_length\"]\n",
    "\n",
    "model, loader, optimizer, scheduler = init_objects(lr, n_epochs, max_length, batch_size)\n",
    "model.to(device)\n",
    "val_acc, _ = train_eval_loop(model, loader, optimizer, scheduler, device, n_epochs)\n",
    "# Obtain Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "s2KaxpkChMts",
    "outputId": "4d7540bb-932b-41ff-c1b1-f439c46d2e79"
   },
   "outputs": [],
   "source": [
    "# Plot the training loss curve\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(_, marker='o', label=\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-AzKsG6hUCV",
    "outputId": "28644510-9361-4280-e9a7-bf868a592897"
   },
   "outputs": [],
   "source": [
    "# Print best hyperparameters and best validation accuracy for Part 2\n",
    "print(\"Best parameters from hyperparameter search with {} pooling:\".format(pooling_type))\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print(f\"Best validation accuracy: {study.best_trial.value:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EXyDLiQhYa7",
    "outputId": "f5be6810-0d20-4599-c177-71a760f3fe66"
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters from hyperparameter search with attention pooling:\")\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xzf7-UdMhblB",
    "outputId": "ea5b2866-9e8a-4acc-b3ea-8d16c51c870a"
   },
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "\n",
    "# Plot the optimization history (objective value vs. trial number)\n",
    "fig_history = vis.plot_optimization_history(study)\n",
    "fig_history.update_layout(title=\"Optuna Optimization History - Part 2 Attention Pooling\")\n",
    "fig_history.show()\n",
    "\n",
    "# Plot the parameter importances (which hyperparameters impacted the results most)\n",
    "fig_importance = vis.plot_param_importances(study)\n",
    "fig_importance.update_layout(title=\"Optuna Parameter Importances - Part 2 Attention Pooling\")\n",
    "fig_importance.show()\n",
    "\n",
    "# Plot the slice plot to visualize the relationship between hyperparameter values and evaluation metric\n",
    "fig_slice = vis.plot_slice(study)\n",
    "fig_slice.update_layout(title=\"Optuna Slice Plot - Part 2 Attention Pooling\")\n",
    "fig_slice.show()\n",
    "\n",
    "# Plot the parallel coordinate plot to inspect the multidimensional search space\n",
    "fig_parallel = vis.plot_parallel_coordinate(study)\n",
    "fig_parallel.update_layout(title=\"Optuna Parallel Coordinate Plot - Part 2 Attention Pooling\")\n",
    "fig_parallel.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
